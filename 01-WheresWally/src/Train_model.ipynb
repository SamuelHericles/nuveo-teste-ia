{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Train_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelHericles/nuveo_challenge/blob/main/01-WheresWally/src/Train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPEEa0-XwMvf"
      },
      "source": [
        "# Initial considerations\n",
        "\n",
        "Utilizing the object detection approach for search Wally in pictures, the model architecture model was the Fast RCNN (see this link: https://arxiv.org/abs/1506.01497). The pyTorch framework has provided the fasterrcnn_resnet50_fpn pre-trained model but needed to be trained with our dataset, so this notebook has prepared an image dataset for the training model. Unfortunately, I don't get good results because it's a new world for me, and passed many hours of study and understanding image processing and objection detection in the literature.\n",
        "\n",
        "I based on these links:\n",
        " - https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n",
        " - https://www.kaggle.com/pestipeti/pytorch-starter-fasterrcnn-train\n",
        " - https://www.kaggle.com/aryaprince/getting-started-with-object-detection-with-pytorch\n",
        " - http://www.galirows.com.br/meublog/opencv-python/opencv2-python27/capitulo2-deteccao/reconhecimento-objetos/\n",
        " - https://medium.com/ensina-ai/detec%C3%A7%C3%A3o-de-objetos-pr%C3%B3prios-para-n%C3%A3o-cientista-de-dados-b7fab2aa0e88\n",
        " - https://www.lapix.ufsc.br/ensino/visao/visao-computacionaldeep-learning/deteccao-de-objetos-em-imagens/\n",
        "\n"
      ],
      "id": "pPEEa0-XwMvf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13VTUgD-Igy0",
        "outputId": "53e326d8-8079-4302-97a9-3762025b4554"
      },
      "source": [
        "%shell\n",
        "\n",
        "!git clone https://github.com/SamuelHericles/nuveo_challenge.git\n",
        "!git clone https://SamuelHericelsBit@bitbucket.org/SamuelHericlesBit/model-nuveo-challenge.git"
      ],
      "id": "13VTUgD-Igy0",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nuveo_challenge'...\n",
            "remote: Enumerating objects: 358, done.\u001b[K\n",
            "remote: Counting objects: 100% (358/358), done.\u001b[K\n",
            "remote: Compressing objects: 100% (232/232), done.\u001b[K\n",
            "remote: Total 358 (delta 129), reused 337 (delta 118), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (358/358), 62.36 MiB | 24.60 MiB/s, done.\n",
            "Resolving deltas: 100% (129/129), done.\n",
            "Cloning into 'model-nuveo-challenge'...\n",
            "Unpacking objects: 100% (3/3), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq_toHCtqBW1"
      },
      "source": [
        "# 0. Import needed"
      ],
      "id": "Pq_toHCtqBW1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54dc286f"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
      ],
      "id": "54dc286f",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqD8xIm_qIdA"
      },
      "source": [
        "# 1. Functions are made for iterate image sample into data loader\n",
        "\n",
        "\n"
      ],
      "id": "XqD8xIm_qIdA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE0l_ZkMtyGK"
      },
      "source": [
        "# 1.1 Prepare dataset"
      ],
      "id": "pE0l_ZkMtyGK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "3a4a735e"
      },
      "source": [
        "def collate_fn(batch):\n",
        "  \"\"\"  \n",
        "    This function transforms a images bath in tuple iterator\n",
        "\n",
        "    @param batch - images batches\n",
        "\n",
        "    @return a batch iterator\n",
        "  \"\"\"\n",
        "  return tuple(zip(*batch))\n",
        "    \n",
        "class Averager:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "          This class works to calculate the mean of loss in training runtime .\n",
        "        \"\"\"\n",
        "          \n",
        "        self.current_total = 0.0\n",
        "        self.iterations = 0.0\n",
        "\n",
        "    def send(self, value):\n",
        "        \"\"\"\n",
        "            Update counter number iteration and value losses.\n",
        "\n",
        "            @param value -  info loss dict values\n",
        "        \"\"\"\n",
        "        self.current_total += value\n",
        "        self.iterations += 1\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        \"\"\"\n",
        "              Calculate current iteration and mean of loss dict values.\n",
        "        \"\"\"        \n",
        "\n",
        "        if self.iterations == 0:\n",
        "            return 0\n",
        "        else:\n",
        "            return 1.0 * self.current_total / self.iterations\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "            Reset counter number iteration and value losses.\n",
        "        \"\"\"        \n",
        "        self.current_total = 0.0\n",
        "        self.iterations = 0.0\n",
        "\n",
        "class WallynDataset():\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "            This class is to pre-processing image, put target in correct type\n",
        "            in line of the fasterrcnn_resnet50_fpn suport.\n",
        "        \"\"\"            \n",
        "        # load all image files, sorting them to ensure that they are aligned\n",
        "        self.imgs = list(sorted(os.listdir('/content/nuveo_challenge/01-WheresWally/data/TrainingSet/images')))\n",
        "        self.centroids = list(sorted(os.listdir('/content/nuveo_challenge/01-WheresWally/data/TrainingSet/json')))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "          Make the dataloader get a image and your target\n",
        "\n",
        "          @param idx - index of image\n",
        "\n",
        "          @return img - image treated\n",
        "          @return target - target of image\n",
        "          @return imgs[idx] - file name image\n",
        "\n",
        "        \"\"\"        \n",
        "        # load images\n",
        "        img_path = os.path.join('/content/nuveo_challenge/01-WheresWally/data/TrainingSet', \"images\", self.imgs[idx])\n",
        "        img = cv2.imread(f'{img_path}', cv2.IMREAD_COLOR)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "\n",
        "        # Torch convert to float32 and divide for beetween 0 and 1.\n",
        "        img_shape = img.shape\n",
        "        img = torch.tensor(img, dtype=torch.float32)\n",
        "        img = torch.reshape(img,(3, img_shape[0], img_shape[1]))\n",
        "        img /= 255.0\n",
        "\n",
        "        # Get points for to calculate the max and min image border points\n",
        "        points_path = os.path.join('/content/nuveo_challenge/01-WheresWally/data/TrainingSet', \"json\", self.centroids[idx])        \n",
        "        json_uploaded = open(f'{points_path}','r')\n",
        "\n",
        "        json_file = json.loads(json_uploaded.read()) \n",
        "        points = json_file['shapes'][0]['points']\n",
        "\n",
        "        xmax, ymax = max(points)\n",
        "        xmin, ymin = min(points)\n",
        "\n",
        "        xmin2 = min(xmax, xmin)\n",
        "        xmax2 = max(xmax, xmin)\n",
        "\n",
        "        ymin2 = min(ymax, ymin)\n",
        "        ymax2 = max(ymax, ymin)\n",
        "\n",
        "        boxes = [xmin2, ymin2, xmax2, ymax2]\n",
        "\n",
        "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
        "        boxes = torch.reshape(boxes, (1, 4))\n",
        "\n",
        "        # there is only one class\n",
        "        labels = torch.ones((1,), dtype=torch.int64)\n",
        "        \n",
        "        # # suppose all instances are not crowd\n",
        "        iscrowd = torch.zeros((1,), dtype=torch.int64)\n",
        "        \n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target['iscrowd'] = iscrowd\n",
        "\n",
        "        return img, target, self.imgs[idx]"
      ],
      "id": "3a4a735e",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkDlUYBqj7w7",
        "outputId": "26f27289-66c2-4051-d6f1-819aa4a2f760"
      },
      "source": [
        "#check output\n",
        "dataset = WallynDataset()\n",
        "dataset[0]"
      ],
      "id": "DkDlUYBqj7w7",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0471, 0.4510, 0.1412,  ..., 0.4000, 0.1569, 0.0706],\n",
              "          [0.4275, 0.1961, 0.0510,  ..., 0.1843, 0.0392, 0.3373],\n",
              "          [0.1843, 0.0706, 0.3686,  ..., 0.0039, 0.2000, 0.1882],\n",
              "          ...,\n",
              "          [0.3922, 0.1412, 0.0353,  ..., 0.2078, 0.0353, 0.3490],\n",
              "          [0.2118, 0.0157, 0.3294,  ..., 0.0275, 0.2235, 0.1804],\n",
              "          [0.0353, 0.4392, 0.1137,  ..., 0.4392, 0.1882, 0.0431]],\n",
              " \n",
              "         [[0.4314, 0.1765, 0.0196,  ..., 0.1843, 0.0471, 0.3608],\n",
              "          [0.2235, 0.0471, 0.3608,  ..., 0.0588, 0.2431, 0.2039],\n",
              "          [0.0196, 0.4314, 0.1020,  ..., 0.4118, 0.1569, 0.0471],\n",
              "          ...,\n",
              "          [0.8314, 0.6745, 0.9804,  ..., 0.0118, 0.2275, 0.2039],\n",
              "          [0.0196, 0.4157, 0.1020,  ..., 0.4235, 0.1765, 0.0941],\n",
              "          [0.4706, 0.2235, 0.0353,  ..., 0.8588, 0.6510, 0.9647]],\n",
              " \n",
              "         [[0.8275, 0.6706, 0.9765,  ..., 0.0196, 0.2275, 0.1961],\n",
              "          [0.0196, 0.4157, 0.1098,  ..., 0.3922, 0.1451, 0.0275],\n",
              "          [0.4157, 0.1647, 0.0118,  ..., 0.7882, 0.6471, 0.9608],\n",
              "          ...,\n",
              "          [0.0314, 0.4157, 0.1137,  ..., 0.4353, 0.1961, 0.0314],\n",
              "          [0.4157, 0.1765, 0.0275,  ..., 0.1961, 0.0510, 0.3490],\n",
              "          [0.1961, 0.0275, 0.3255,  ..., 0.0039, 0.2235, 0.1882]]]),\n",
              " {'boxes': tensor([[432., 467., 682., 683.]]),\n",
              "  'iscrowd': tensor([0]),\n",
              "  'labels': tensor([1])},\n",
              " 'wally_000.jpg')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM0PcpPFt7mS"
      },
      "source": [
        "# 2. Training model\n",
        "\n",
        "# 2.1 Upload model pre-trained and after to train with our dataset\n"
      ],
      "id": "gM0PcpPFt7mS"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4A-8yyXyliw"
      },
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "# get number of input features for the classifier\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "# replace the pre-trained head with a new one\n",
        "# 1 class (wheat) + background\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes=2)"
      ],
      "id": "V4A-8yyXyliw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "882bmwxouFtv"
      },
      "source": [
        "# 2.2 Transform dataset in iterate torch DataLoader"
      ],
      "id": "882bmwxouFtv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zcBc-f0ylgb"
      },
      "source": [
        "# use our dataset and defined transformations\n",
        "dataset = WallynDataset()\n",
        "\n",
        "# split the dataset in train and test set\n",
        "torch.manual_seed(1)\n",
        "indices = list(i for i in range(105))\n",
        "dataset = torch.utils.data.Subset(dataset, indices)\n",
        "\n",
        "# define training and validation data loaders\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size = 4, shuffle = False, num_workers=2,\n",
        "    collate_fn = collate_fn)"
      ],
      "id": "5zcBc-f0ylgb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkbzsw1_uSH0"
      },
      "source": [
        "# 2.4 Configures the optimizer\n",
        "\n",
        "Base on this link(https://ichi.pro/pt/tutorial-de-deteccao-de-objetos-com-torchvision-143730852624127) learning rate arround 0.0001 and 0.0005 and weight_decay 0.0001 and 0.0005 are good for start training Faster RCNN model.\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "Lkbzsw1_uSH0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_94B-x2ylbK"
      },
      "source": [
        "# Define device avaliable for train enviroment.\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.Adam(params, lr=0.0003, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "# Define number of epochs\n",
        "num_epochs = 3"
      ],
      "id": "C_94B-x2ylbK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSKrDRKXvYzk"
      },
      "source": [
        "# 2.5 Train model step\n",
        "\n",
        "\n",
        "I try many time for get best loss mean (close 0.01), so there is."
      ],
      "id": "FSKrDRKXvYzk"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2qxDJTxylYx",
        "outputId": "c7ee3903-f233-4932-c019-a446ac9ec88e"
      },
      "source": [
        "loss_hist = Averager()\n",
        "itr = 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    loss_hist.reset()\n",
        "    \n",
        "    for images, target, _ in data_loader:\n",
        "      \n",
        "      #Get image and target and set your device for dataloader type\n",
        "      images = list(image.to(device) for image in images)\n",
        "      target = [{k: v.to(device) for k, v in t.items()} for t in target]\n",
        "\n",
        "      # Forward step\n",
        "      loss_dict = model(images, target)\n",
        "      \n",
        "      # Get loss dict values information\n",
        "      losses = sum(loss for loss in loss_dict.values())\n",
        "      loss_value = losses.item()\n",
        "\n",
        "      loss_hist.send(loss_value)\n",
        "\n",
        "      # Backward step\n",
        "      optimizer.zero_grad()\n",
        "      losses.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if itr % 10 == 0:\n",
        "          print(f\"Iteration #{itr} loss: {loss_value}\")\n",
        "\n",
        "      itr += 1\n",
        "    lr_scheduler.step()\n",
        "    print(f\"Epoch #{epoch} loss: {loss_hist.value}\")   "
      ],
      "id": "L2qxDJTxylYx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration #10 loss: 0.24474990367889404\n",
            "Iteration #20 loss: 0.17614886164665222\n",
            "Epoch #0 loss: 0.47539590851024344\n",
            "Iteration #30 loss: 0.1435394585132599\n",
            "Iteration #40 loss: 0.3151240050792694\n",
            "Iteration #50 loss: 0.18175429105758667\n",
            "Epoch #1 loss: 0.3041205334442633\n",
            "Iteration #60 loss: 0.17453822493553162\n",
            "Iteration #70 loss: 0.18782402575016022\n",
            "Iteration #80 loss: 0.27125638723373413\n",
            "Epoch #2 loss: 0.2884931398762597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlaIiV8Hv4xc"
      },
      "source": [
        "# 6. Save the model\n",
        "\n",
        "I utilize torh.save, not onnx, because I have some problem with version package."
      ],
      "id": "mlaIiV8Hv4xc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlW9CGjHlyDh"
      },
      "source": [
        "torch.save(model.state_dict(), os.path.join('/content/nuveo_challenge/01-WheresWally/', \"models\", 'model.pt'))"
      ],
      "id": "PlW9CGjHlyDh",
      "execution_count": null,
      "outputs": []
    }
  ]
}